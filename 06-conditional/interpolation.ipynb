{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T02:13:37.720182Z",
     "start_time": "2024-11-29T02:13:37.716581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import trange\n",
    "import torch\n",
    "\n",
    "from main import Model, NoiseScheduler, DATASETS, denormalize, CONFIGS, parse_args, ACTIVATION_FUNCTIONS"
   ],
   "id": "9ce7f8a9ba1ca3f1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _test(device, noise_scheduler, model, file_path=\"img.png\", progress=False, dataset='cifar10', resolution=None,\n",
    "          conditional=True):\n",
    "    # Use seed\n",
    "    torch.manual_seed(0)\n",
    "    dataset = DATASETS[dataset]\n",
    "    n, nr = 256, 16\n",
    "    classes = None\n",
    "    if conditional and dataset.name in ['cifar10', 'mnist']:\n",
    "        n, nr = 100, 10\n",
    "        classes = torch.arange(10).repeat_interleave(10).to(device)\n",
    "    elif conditional and dataset.name == 'cifar100':\n",
    "        n, nr = 100, 10\n",
    "        classes = torch.arange(100).to(device)\n",
    "    elif conditional:\n",
    "        raise ValueError(f\"Conditional model is not supported for {dataset.name}\")\n",
    "\n",
    "    x = torch.randn(n, dataset.image_channels, resolution, resolution, device=device)\n",
    "\n",
    "    if progress:\n",
    "        steps = trange(noise_scheduler.steps - 1, -1, -1)\n",
    "    else:\n",
    "        steps = range(noise_scheduler.steps - 1, -1, -1)\n",
    "\n",
    "    for step in steps:\n",
    "        with torch.no_grad():\n",
    "            t = torch.tensor(step, device=device).expand(x.size(0), )\n",
    "            if conditional:\n",
    "                pred_noise = model(x, t, classes)\n",
    "            else:\n",
    "                pred_noise = model(x, t)\n",
    "            x = noise_scheduler.sample_prev_step(x, t, pred_noise)\n",
    "\n",
    "    x = denormalize(x).clamp(0, 1)\n",
    "\n",
    "    # Create an image grid\n",
    "    grid = make_grid(x, nrow=nr, padding=2)\n",
    "    grid = to_pil_image(grid)\n",
    "    grid.save(file_path)\n",
    "    torch.seed()  # Reset seed\n",
    "\n",
    "\n",
    "def test(model_channels=32,\n",
    "         activation_fn=torch.nn.SiLU,\n",
    "         num_res_blocks=2,\n",
    "         channel_mult=(1, 2, 2, 2),\n",
    "         dropout=0.1,\n",
    "         attention_resolutions=(2,),\n",
    "         gpu=None,\n",
    "         model_path='model.pth',\n",
    "         file_path='img.png',\n",
    "         dataset='cifar10',\n",
    "         conditional=True):\n",
    "    dataset = DATASETS[dataset]\n",
    "    device = torch.device(f'cuda:{gpu}' if gpu is not None else 'cpu')\n",
    "    noise_scheduler = NoiseScheduler().to(device)\n",
    "    model = Model(image_channels=dataset.image_channels,\n",
    "                  model_channels=model_channels,\n",
    "                  activation_fn=activation_fn,\n",
    "                  num_res_blocks=num_res_blocks,\n",
    "                  channel_mult=channel_mult,\n",
    "                  dropout=dropout,\n",
    "                  attention_resolutions=attention_resolutions,\n",
    "                  num_classes=dataset.num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    _test(device, noise_scheduler, model, file_path, progress=True, dataset=dataset.name, conditional=conditional)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:57:32.544855Z",
     "start_time": "2024-11-29T01:57:32.539604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NoiseSchedulerParameterized(NoiseScheduler):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def sample_prev_step_z(self, xt, t, pred_noise, z):\n",
    "        t = t.view(-1, 1, 1, 1)\n",
    "        z[t.expand_as(z) == 0] = 0\n",
    "\n",
    "        mean = (1 / torch.sqrt(self.alpha[t])) * (xt - (self.beta[t] / torch.sqrt(1 - self.alpha_bar[t])) * pred_noise)\n",
    "        var = ((1 - self.alpha_bar[t - 1]) / (1 - self.alpha_bar[t])) * self.beta[t]\n",
    "        sigma = torch.sqrt(var)\n",
    "\n",
    "        x = mean + sigma * z\n",
    "        return x"
   ],
   "id": "71f647728c9ad69b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T02:08:03.299727Z",
     "start_time": "2024-11-29T02:08:03.295102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = CONFIGS['mnist']\n",
    "args = parse_args(args=config)"
   ],
   "id": "3dcb9c28f2581c94",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T02:08:05.452863Z",
     "start_time": "2024-11-29T02:08:05.447493Z"
    }
   },
   "cell_type": "code",
   "source": "args",
   "id": "d154a30f6a5e3188",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(command='train', dataset='mnist', batch_size=256, epochs=2000, steps=200000, val_interval=4000, lr=0.001, grad_clip=1.0, grad_accum=1, warmup=5000, ema_decay=0.9999, model_channels=32, activation='silu', num_res_blocks=1, channel_mult=[1, 1, 2], hflip=False, dropout=0.1, attention_resolutions=[2], gpu=None, model='model.pth', save_checkpoints=True, log_interval=1, output_dir='output', file_path='img.png', conditional=False, resolution=None, progress=True, config=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T02:13:41.597510Z",
     "start_time": "2024-11-29T02:13:41.591990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = DATASETS[args.dataset]\n",
    "activation_fn = ACTIVATION_FUNCTIONS[args.activation]"
   ],
   "id": "dfb0ca53de11e01c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T02:13:42.794437Z",
     "start_time": "2024-11-29T02:13:42.777364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model(image_channels=dataset.image_channels,\n",
    "              model_channels=args.model_channels,\n",
    "              activation_fn=activation_fn,\n",
    "              num_res_blocks=args.num_res_blocks,\n",
    "              channel_mult=args.channel_mult,\n",
    "              dropout=args.dropout,\n",
    "              attention_resolutions=args.attention_resolutions,\n",
    "              num_classes=dataset.num_classes)"
   ],
   "id": "25668289db723513",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6c15222546de3175"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
